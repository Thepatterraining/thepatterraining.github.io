---
title: CMU15445笔记
date: 2023-04-26 10:12:47
tags: ['数据库','数据库原理','sql','mysql']
category: CMU15445
article: CMU15445笔记
---

# CMU15445笔记

## 高级SQL

PostegreSQL:由伯克利大学开发，是之前开发Ingres的人开发的。

IBM的DB2支持SQL,所以SQL成为了标准。

数据库支持SQL,最低要支持SQL-92标准。

下面的sql在postgreSQL中会报错，mysql中如果`sql_mode`是`ansi`也会报错，如果`sql_mode`是`traditional`就不会报错，而是会随机选一个cid展示出来。

```SQL
select avg(s.gpa), e.cid from enrolled as e,student as s
where e.sid = s.sid;
```

### 字符串处理

|名称|大小写|引号|字符串拼接|
|:---|:----|:----|:----|
|SQL-92| 敏感的 | 单引号| \|\| |
|PostgreSQL| 敏感的 | 单引号| + |
|mysql| 不敏感的 | 单引号/双引号 | concat / 空格 |
|SQLite| 敏感的 | 单引号/双引号 | + |
｜DB2| 敏感的 | 单引号|  \|\| |
| Oracle| 敏感的 | 单引号| \|\| |


### 时间日期处理

|名称|当前日期 NOW() | 当前日期 CURRENT_TIMESTAMP() | 当前日期 CURRENT_TIMESTAMP | 日期差值 |
|:---|:----|:----|:----|:----|
|PostgreSQL| 2023-04-26 14:27:01.790522+08 | 不支持|2023-04-26 14:27:32.280334+08 | select DATE('2018-08-29') - DATE('2018-01-01'); 结果240  |
|mysql| 2023-04-26 14:28:36 | 2023-04-26 14:28:44 | 2023-04-26 14:28:56 | select DATEDIFF(DATE("2018-08-29"),DATE("2018-01-01")); 结果240 |
|SQLite| 不支持 | 不支持 | 2023-04-26 06:30:47 | select CAST((julianday('2018-08-29') - julianday('2018-01-01')) as INT) as days; 结果 240 |

### 复制表数据

create table会创建表，insert into需要表已经存在。
```SQL
create table student2 (
    select * from student
);

insert into student2(
    select * from student
);
```

### 获取id最大的一个学生数据

下面的是错误做法，因为不知道id最大的name是谁，会报错，如果sql_mode=tranditional，会执行成功，但是name是随机的。
```SQL
select MAX(e.sid),s.name from enrolled as e,student as s
where e.sid = s.sid
```

下面的在postgresql和mysql都可以执行成功，并获取到id最大的name数据。
```SQL
select sid, name from student
where sid in (select max(sid) from enrolled)
```

下面的SQL在postgresql中可以执行成功，结果和上面的一样，而在mysql8中报错`This version of MySQL doesn't yet support 'LIMIT & IN/ALL/ANY/SOME subquery'`

```SQL
select sid, name from student
where sid in (select sid from enrolled order by sid desc limit 1);
```

### 获取没有学生报名的课程

下面的sql在postgresql 和 mysql 中都可以得到正确的结果
```SQL
select * from course 
where not exists(select * from enrolled where course.cid = enrolled.cid);
```

### window窗口

`ROW_NUMBER`和`RANK`都需要和`OVER`一起使用。

- ROW_NUMBER(): 显示当前行号
- RANK() : 显示排序后的排名，如果没有排序，都是1
- OVER()
    - PARTITION BY 进行分组
    - GROUP BY 进行分组
    - ORDER BY 排序

![001](../images/15445001.png)

![002](../images/15445002.png)

![003](../images/15445003.png)

#### 获取每个课程中分数最高的学生信息

下面的SQL，在postgresql中执行成功，mysql8执行报错。

首先查询所有课程信息，并按照课程分组，按照分数排序。

```SQL
SELECT *,
RANK() OVER (PARTITION BY cid ORDER BY grade ASC)
AS rank FROM enrolled
```

![004](../images/15445004.png)

接着搜索上表中分数为1，也就是分数最高的学生。也就是每个课分数最高的学生信息。

```SQL
SELECT * FROM (
    SELECT *,
    RANK() OVER (PARTITION BY cid
    ORDER BY grade ASC)
    AS rank FROM enrolled) AS ranking
WHERE ranking.rank = 1
```

![005](../images/15445005.png)


### CTE(common table expressions)

使用`CTE`实现获取每个课程中分数最高的学生信息。

通过`WITH`语句来声明一个临时表。表名`cteSource`，表的内容就是最的sid，通过`SELECT MAX(sid) FROM enrolled`查询出来的结果。字段名叫`maxId`。

然后在查询语句里面就可以连接`cteSource`表，然后通过sid = cteSource.maxId 来获取到sid最大的用户信息。

```SQL
WITH cteSource (maxId) AS (
    SELECT MAX(sid) FROM enrolled
)
SELECT name FROM student, cteSource
WHERE student.sid = cteSource.maxId
```

还有一些其他的用法，比如:

```SQL
WITH cte1 (col1) AS (
SELECT 1
),
cte2 (col2) AS (
SELECT 2
)
SELECT * FROM cte1, cte2;
```

## 数据存储1

页的三个概念
1. 硬件上的页面(通常是4KB)
2. 操作系统上的页面(4KB)
3. 数据库页面(1-16KB)

系统设计目标：给应用程序一个错觉，能提供足够的内存将整个数据库存入内存中。
实现：谨慎的最小化每次从磁盘读取内容或运行查询时所带来的影响。
流程：
- 查询执行器：向内存中的`buffer pool`请求查询内容。
- buffer pool: 如果数据所在的页已经在buffer pool中，就直接返回。如果数据所在的页不在buffer pool中，就向磁盘中的`database file`请求。
- database file: 有页目录，还有具体的页，数据存在页中，查询页目录找到对应的页返回给`buffer pool`。

![006](../images/15445006.png)

上面的步骤操作系统本身就可以实现，比如使用`mmap`，但是操作系统是统一的动作，遇到一些问题不知道该如何处理，而DBMS则可以根据不同的情况做不同的处理，进行优化。像主流的`mysql`,`SqlServer`,`Oracle`都没有用`mmap`。`mongoDB`早期使用的`mmap`，后面也是用`WiredTiger`替换掉了`mmap`。

DBMS自己实现的话，主要关心的两个问题:
1. 如何表示磁盘上文件的数据
2. 如何管理内存以及在硬盘间移动数据

### 如何表示磁盘上文件的数据

数据库的数据最终以文件的形式放在磁盘中。通过文件读写将数据读写到文件中。文件有特定的格式，具体的内容有数据库进行解析然后展示在数据库中。这就是`storage manager` or `storage engine`。

`storage manager`负责文件的读写工作。所有的文件（不管是一个或者多个）以 `page` 的形式存储，管理多个 `page` 组成的集合。

一个`page`就是一个固定大小的数据块。`page` 可以保存任何东西，`tupe`, `metadata`, `indexes`, `log`等等。每个`page`有唯一的ID.

有些`page`要求是独立的，自包含的(self-contained)。比如`mysql的InnoDB`。因为这样的话一个表的元数据和本身的数据内容在一起，如果发生问题的话，可以找回元数据和数据。如果元数据和数据在不同的`page`中，如果发生问题导致元数据的`page`丢失，那么数据则恢复不了了。

`indirection`层记录page ID的相对位置，方便找到对应的偏移量。这样page目录就能找到对应的page。 

堆存储
- 无序的，保存的顺序和存储的顺序无关。
- 需要读写page
- 遍历所有的page
- 需要元数据记录哪些是空闲的page,哪些是已经使用的page。
- 使用 `page directory` 方式来表示文件。


page directory
- 存储page ID和所在位置的关系
- 存储page的空闲空间信息

page header
- page 大小
- checksum 校验和
- DBMS版本信息
- 事务可见性
- 压缩信息

page内部，通常使用的是slotted pages
- tupe storage
    - 记录page数，也就是page内部可插入的偏移量
    - 一个一个tupe按照顺序存储

![007](../images/15445007.png)

- slotted pages
    - slot array 存储插槽信息的偏移量，通过他找到对应的tuple
    - 支持可变长度的 tuple
    - 但是会产生一些碎片空间，因为太小，tuple放不下。

![008](../images/15445008.png)


不同的DBMS有不同的名称，来表示数据的唯一位置，比如`postgresql`的`ctid`,`oracle`的`rowid`。`ctid`由`page id`和`slot number`组成。

![009](../images/15445009.png)

tuple
- header
- 列1
- 列2
- 列n

## 数据存储2

可变长度的数据`varchar`,`varbinary`,`text`,`blob`,他们的长度存在header里面。

日期时间类型存储的是时间戳。

float/real: 是浮点数，cpu支持浮点数运算，优点是速度快，但是会精度缺失
decimal: 是定点数，运算速度慢，但是精度高。

large values，应该避免这样，因为维护overflow page很麻烦。
- tuple中存储另外一个page页的指针，将具体数据存放到另外一个page页中。
- postgresql中叫`toast`，如果数据大于2KB，就会放到toast中，tuple中只存储指针。
- mysql中叫`overflow page`，如果数据大于1/2的page大小，就会放进去，tuple中只存储指针。

外部存储
- tuple中存储指向外部文件的指针或者文件地址。

catalogs 用来存储数据库元信息，大多数数据库将这些信息存到一张表里面
- 表，字段，索引，视图等
- 用户，权限，安全等
- 内部数据统计等
- infomation schemal api 通过这个来获取catalogs信息
    - mysql
        - show tables 获取所有的表
        - describe table_name 获取表的信息
    - postgresql
        - \d or \d+ 获取所有的表
        - \d table_name 获取表信息

OLTP
- 通常是业务侧使用的传统数据库，比如oracle,postgresql,mysql
- 小的业务多次执行，比如多个简单的插入，更新，查询

OLAP
- 通常是大数据，数据分析来使用，比如Hbase等，支持复杂的数据查询
- OLAP位于OLTP的后方

HTAP
- OLTP和OLAP的混合，两个都可以做

N-ary 模型
- 行存储模型
- page里面是按行存储的，每个tuple就是一行
- 查找数据的弊端是会加载一个page的时候会加载不需要的行数据
- 查找的优势是数据都在一起

Decomposition 模型
- 列存储模型
- 一个page里面是一列数据
- 优势是查找的时候不会加载不需要的数据
- 劣势是查找的数据不在一起，需要去各个page里面找

## buffer pool 和内存管理

时间管理
- 将数据写入磁盘的何处
- 目标是经常被一起使用的pages放在磁盘中也是一起的地方。

空间管理
- 何时将pages读入内存，何时将pages写入磁盘
- 目标是最小化的解决必须从磁盘读取数据这个事

frame
- buffer pool中的一块内存区域
- 相当于page里面的slot

page table
- 记录pages在当前buffer pool中的位置,通过page table 和 page id可以知道在哪个frame中。

page 里面记录一些元数据
- dirty flag: 记录是否被修改过，也就是常说的"脏数据标记"
- 引用计数器： 记录有多少线程在使用这个数据

lock and latch
- lock在数据库中指high-level的东西，可以保护数据库，数据表，数据
- latch保护内部的东西，数据结构，内存区域

全局策略
- 针对所有的查询或者事务的策略

局部策略
- 针对单个查询或者事务的策略
- 可以对单个优化，虽然对全局可能不好

多buffer pool
- 通过使用多个buffer pool可以根据不同的table放入不同的buffer pool进行不同的优化。也可以通过其他的策略使用多个buffer pool
- 由于有多个buffer pool,减少了锁争抢和锁等待的时间。
- mysql中通过hash确定数据是否在buffer pool，然后通过取余确定在哪个buffer pool

预取数据
- 顺序扫描的时候预先把后面的page取到buffer pool中。这一步mmap也可以实现
- 索引扫描的时候预先把索引中需要用到的后面的page取到buffer pool中。这一步mmap实现不了，这也是数据库自己实现buffer pool的优势。

扫描共享
- 共享扫描到的page内容
- 如果查询1需要扫描page1,page2,page3,page4的内容并且已经扫描到了page3,这个时候page1已经扫描完了被从buffer pool中丢弃了
- 这时候有一个查询2也需要扫描所有的pages，如果从page1开始扫描，就会把page1再次读入buffer pool，但是这样是低效率的，所以可以先共享查询1的page数据，先扫描page3,然后page4，这时候查询1执行完毕，在回头扫描page1,page2。
- mysql不支持

buffer pool绕过
- 单独开辟一个本地内存区域来用，而不是使用buffer pool
- 可以避免操作page table带来的开销（latch锁住的开销）
- 可以避免污染buffer pool
- 适合数据量不大的情况
- mysql5.7不支持

os page cache
- 操作系统的文件缓存，当使用fopen,fread,fwrite的时候会先从操作系统缓存中读取文件内容。
- 只有postgresql使用了这个。
- 通过 direct IO可以不使用这个
- 使用它会导致有两个缓存，buffer pool 和 os page cache。不好控制。

内存替换策略
- LRU 最近最少使用
- Clock 把所有的page放成一个圈，每个page有一个标志位，如果为0表示没有被使用过，1被使用过，淘汰的时候淘汰0的，再把1改成0.
- LRUK 记录使用的次数k，达到次数才放到缓存里面，淘汰的时候比对两次的时间间隔，间隔长的认为是最近最少使用

两种写出方案需要做权衡，取舍
- 如果写出dirty flag的数据然后读取新数据，就会产生2次IO。通常会有一个定时任务线程去将dirty flag的数据写入磁盘，写入之前必须要先将操作日志写入磁盘。
- 如果直接读取新数据就只有1次IO，但是这样有可能把下次会用到的数据丢弃。

## hash table

hash function
- 最快的是facebook 的 xxhash

hash schema
- liner probe hashing
    - 如果要插入的位置有值了，就往下扫描，扫描到空的位置插入
    - 删除的时候可以增加一个`墓碑`标记，这样就知道这里是有数据的不是空，查找的时候就会继续往下扫描而不会是没找到
    - 删除的时候还可以把后面的数据往前移动，但是这样有的数据就不再原来的位置了，就找不到了。因为只会往下扫描不会往上扫描
- robin hood hashing
    - 记录`距离数`，表示插入的位置和应该插入的位置的距离。从0开始。
    - 插入的时候判断距离数，进行`劫富济贫`，如果你向下扫描到距离数为3的地方插入，而在距离数为2的地方的数据x，x的距离数比你小，比如是0，1.那么你就占据这里，你插入距离数为2的地方，而将x插入你下面，x的距离数会+1.
    - 从整体来看，这个方法牺牲了插入的效率，将数据的距离数变得更加平均
- cuckoo hashing
    - 该方法使用两个或多个`hash table`来记录数据，对A进行两次hash，得出两个hash table中的插入位置，随机选择一个进行插入
    - 如果选择的插入位置已经有数据了，就选择另一个插入
    - 如果两个都有数据了，就占据一个，然后对这个位置上之前的数据B再次hash选择其余位置。

动态hash table
- chained hashing
    - 把所有相同hash的组成一个bucket链表，然后一直往后面增加
    - java的hash table默认就是这样的
- extendible hashing
    - 对 chained hashing 的扩展
    - 有一个slot array，在slot array上有一个 counter, 如果counter = 2，代表看hash以后的数字的前两个bit,slot array就有4个位置，分别是00,01,10,11
    - 每个slot指向一个bucket
    - hash以后找到前两位对应的slot指向的bucket，将数据放进去，如果满了，放不下了就进行拆分
    - 将slot array的counter扩容为3，看前3个bit，slot array变成了8个位置
    - 只将这个满了的bucket拆分成2个，其余的不变，重新进行slot的映射
    - 再次hash这个值，看前3个bit找到对应的slot,在找到对应的bucket，然后插入进去
- linear hashing
    - 对 extendible hashing 的扩展
    - 去掉了 conter，因为他每次加1，都会扩容一倍
    - 增加了`split point`，一开始指向0，然后每次`overflow`需要拆分的时候就拆分split point指向的那个bucket，然后slot array只扩容一个，这个时候出现第二个hash函数并将split point+1
    - 查询的时候如果slot array的位置小于split point，就使用第二个hash函数，因为被拆分了
    - 如果大于等于split point，就使用第一个hash函数

## tree index

- b tree(1971)
- b+ tree (1973)
- b* tree (1977)
- b link tree (1981)

b+ tree 删除和插入的复杂度都是`O(log n)`， b 是 `balance (平衡)`，paper: `the ubiquitous B-tree`

B+ tree,保证每个节点都必须是半满的，对于存放在节点中的key数量来说，key数量至少为`M/2 - 1`个，M为树的高度，key的数量必须小于 `M - 1`,如果当删除数据以后导致key数量小于M/2 - 1个，就会进行平衡，使他满足M/2 - 1个。
> M/2 - 1 ≤ key数量 ≤ M - 1

如果一个中间节点有k个key,那你就会有k+1个非空孩子节点，也就是k+1个指向下方节点的指针。每个节点的内容是一个`指针`和一个`key`

叶子节点之间有连接叶子节点的兄弟指针，这个想法来源于b link tree。每个节点的内容是一个`数据`和一个`key`，数据可以是一个`record id` 也可以是一个 `tuple`

叶子节点的内容，通常key和value是分开存储的，因为搜索的时候并不需要加载value数据
- 元数据
    - isleaf 是否是叶子节点
    - slots 有多少空闲的slot
    - prev 前一个叶子节点的指针
    - next 后一个叶子节点的指针
- key数据
- value数据

b tree 和 b+ tree 的区别
- b tree的中间节点也可以存数据，所以key是不重复的
- b+ tree的中间节点没有数据，所有数据都在叶子节点，所以key有可能既存在中间节点也存在叶子节点。会重复
- b tree的性能在并行处理上更差，因为修改以后需要向上传播也需要向下传播修改，这个时候两边都要增加`latch`
- b+ tree的性能更好，因为只修改叶子节点，所以只需要向上传播，只需要增加一个`latch`

b+ tree 插入
1. 向下扫描，找到对应的叶子节点
2. 如果可以插入就直接插入
3. 如果不可以插入，那么从中间分开，变成两个叶子节点，并将中间的key传递给父节点，插入父节点。
4. 如果父节点可以插入就直接插入并分出一个指针指向新的叶子节点
5. 如果父节点不可以插入重复上述操作3

b+ tree 删除
1. 向下扫描，找到对应的叶子节点，这个时候就会增加`latch`，因为不知道需不需要合并，操作以后才会释放
2. 如果可以删除就直接删除
3. 如果删除后导致key数量 < `M/2 - 1`,那么就会出发合并，因为不满足key数量啦
4. 进行合并的时候删除这个key，然后先查看左右的兄弟节点，是否能直接把数据插入过来，如果可以的话就掠夺一个key过来，然后向上传播
5. 如果不能掠夺，那么就合并到兄弟节点，然后向上传播。

b+ tree 标准填充容量大概是67% - 69%，对于一个大小是8kb的page来说，如果高度为4，大约能记录30 0000个键值对。

b+ tree的查找
- 对于<a,b,c>,查找a=5 and b=3也是可以走索引的，但是hash索引就不行，有些数据库还支持b=3的搜索走索引，比如oracle和sql server

b+ tree的节点大小，机械硬盘的大小最好在1M,ssd的大小在10KB

> 推荐书籍 Modern B-Tree Techniques

对于非唯一索引
- 重复存储，需要注意两个相同的key存储在不同的page中
- value list,key只存储一个，然后所有的value存储成value list

节点内部的搜索
- 线性搜索
- 二分搜索
- interpolation
    - 通过数学计算出线性搜索的起点，提升搜索速度

优化方法
- 前缀压缩
    - 比后缀截断用的更多
    - 存储在page中的key,如果前缀一样的可以提取出来存储一次，然后剩余的数据在存储在key里面
- 后缀截断
    - 存储在中间节点的，用来寻路的key，可以只存储前面的部分，如果后面的不需要可以截断
    - 更新的时候需要进行维护
- 批量插入
    - 如果已经有数据了再建立索引，这个时候不需要从头开始一个个建立，只需要先排序
    - 然后建立所有的叶子节点
    - 在一层层向上建立中间节点
    - 非常普遍的方法，主流数据库都支持
- point willizeing
    - 将节点固定在内存中
    - 对于page来说，直接存储page指针而不是page id，就不需要请求buffer pool了

b+ tree的重复key，通常使用增加`record id`的方式，这种方式影响更小。
- 增加`record id`,`record id`是`page id` + `offset`用来确定tuple的位置。
- 垂直扩展叶子节点，将数据存在里面

部分索引
- 在创建索引的时候添加where条件，只有符合条件的才会进入索引。
- 查询的时候只有符合条件的才会走索引

覆盖索引
- 在创建索引的时候添加联合索引
- 查询的时候所需数据都在索引中，就不需要在找对应的tuple信息了。

函数索引
- 创建索引的时候添加函数信息，比如 MONTH(date), 只对月份创建索引
- 查询的时候 MONTH(date) 就会走索引了，而date就不会走索引了
- 如果创建的时候只创建 date 索引，那么查询的时候 MONTH(date) 就不会走索引

trie index(前缀树)
- 把每个单词建立成树，一层放一个字母

radix tree
- trie index的升级版
- 对于trie index进行了横向的压缩和纵向的压缩

## 索引并发控制

并发控制
- 逻辑正确性
    - 获取id = 5的数据，能正确返回id = 5的数据
- 物理正确性
    - 保护page指针指向正确的page数据，不会触发 segfualt

latch 模式
- 读模式
    - 可以多个线程读取
- 写模式
    - 只有一个线程可以写模式，这个时候其他线程不能读取也不能写入

latch
- blocking os mutex
    - std::mutex m;
    - m.lock();
    - m.unlock();
- test and set spin latch
    - std::atomic_flag latch
    - while(latch.test_and_set()){} // 如果获取到锁就跳出循环
- read - write latch
    - 读锁，获取的时候线程数队列，等待队列，如果能获取就进入线程数队列，不能就进入等待队列
    - 写锁，线程数队列，等待队列，如果能获取就进入线程队列，不能就进入等待队列
    - 如果有一个写锁在等待队列，这个时候在获取读锁也放入等待队列，要不然一直读，写锁就获取不到了

latch crabbing/coupling
- 使用栈保存latchs
- 每个节点都需要一个latch
- 如果当前节点是`安全`的，就可以释放上层的所有latchs
- `安全`：指操作的时候不会触发`拆分`和`合并`。通常read latch都是安全的，write latch 插入的时候如果有足够的空间就是安全的，删除的时候删除以后不会合并就是安全的

乐观锁
- 乐观的认为不需要`合并`和`拆分`。
- 所有的操作都先获取read latch,如果发现需要`合并`和`拆分`，再次从头获取write latch来一遍
- 优点是所有操作都是read latch，可以更好的支持并发
- 缺点是遇到`合并`和`拆分`会再来一遍，而且如果连续的插入都需要合并，就会退化成每个都获取write latch。

叶子节点扫描
- 叶子节点的扫描可能会触发`死锁`，比如两个线程
- 线程1执行读取，读取到了叶子节点1
- 线程2执行写入，在叶子节点2处获取了write latch
- 这个时候线程1在叶子节点1里面没有找到数据，所以要扫描叶子节点2，但是获取read latch的时候卡主了，需要等待
- 而线程2有可能也需要访问叶子节点1，同样等待，产生死锁
- 这个时候可以设置等待时间，超过等待时间则`自杀`，然后重头再来，加入线程1自杀，然后再来一遍，这个时候线程2就可以获取到latch，然后执行下去了

overflow处理
- 来源于b link tree的优化
- 当需要拆分的时候，先拆分叶子节点，这个时候不向`父结点`传播，因为修改父结点需要从头开始获取write latch。
- 这个时候标记父结点需要插入一个key
- 等待下一个修改操作到父结点的时候，获取write latch，然后执行这个插入操作。

## 排序和聚合

排序的好处
- 有序的数据创建索引的时候可以快速的先创建叶子节点，在创建父结点
- 有序的数据在`order by`分组的时候可以更快的分组
- 有序的数据在`distinct`去重的时候可以更快的去重

排序算法
- 在内存中
    - 可以使用各种算法
    - 但是有的数据内存放不下，就需要在磁盘上排序
    - 需要先知道`可以用内存的大小`，这样就知道该内存排序还是磁盘排序
- 在磁盘上
    - 快排会产生更多的随机IO,会更慢
    - 使用`归并排序`更好，分成多个`runs`,对每个run排序，然后在通过`二路归并`生成总的排序，这可以减少随机IO
    - 外部归并排序，需要3个`buffer pool`，2个用来排序run，1个用来二路归并。 
    - 次数：1 + log(n)
    - 总的IO数: 2N * (# of passes)
    - 可以通过`预取`来优化，当对page排序的时候，另外一个线程先取出下次要排序的page。

聚簇索引
- 排序的字段如果建立了聚簇索引，就不需要在排序了，直接可以走聚簇索引拿到排序好的数据

### 聚合

两个实现方法
- 排序
- 哈希，通常哈希更好，因为都在内存中

> group by 和 distinct 本身执行的时候也是需要排序的

hash
1. 分区
    - 可以顺序扫描每个page
    - 对于每个page的key进行hash，然后分区，hash相同的说明key相同，分到一个区里面
    - 这个时候不管distinct还是group by都可以方便的执行了
2. 重新哈希
    - 对于分区以后的数据再次进行hash
    - 再次hash的数据放入一个临时的hash table
    - 处理完一个临时的hash table就把结果写入结果集

排序的聚合实现，以distinct为例：
1. 先执行where条件筛选出符合的`tuple`
2. 再次根据列筛选出符合的列
3. 对于需要排序的列进行排序
4. 顺序扫描排序结果，实现去重，并生成最终结果

哈希的聚合实现，以distinct为例：
1. 先执行where条件筛选出符合的`tuple`
2. 再次根据列筛选出符合的列
3. 对于需要排序的列进行hash，先分区，再重新哈希。
4. 重新哈希的时候生成最终结果。

重新哈希的时候
- avg的话，需要再临时hash table里面存储key的数量和要求平均数的总数。在生成最终结果的时候进行计算平均数
- min的话，临时hash table里面存入最小数，生成最终结果直接取
- max同上
- sum同上
- count同上

## join算法

join输出：数据
- 在join的时候把两张表的数据全部输出给下一个处理器，这包括了表的所有字段
- 好处是，接下来的处理不需要再拿其他字段了，所有字段都有了
- 坏处是，Join的时候数据量很大，因为有所有字段
- 可以进行优化，在join的时候只获取需要的字段

join输出：record id
- 在join的时候，只获取on的字段和record id，然后需要其他字段的时候在通过 record id去获取，这个很适合列存储数据库
- 第一个使用的是`vertica`列存储数据库，不过现在已经不用了

如何判断两个join算法的好坏？
- 通过IO来计算
- 假设左表R有M个page,m个tuple
- 右表S有N个page,n个tuple

join算法
- Nested Loop Join
    - simple/stupid
    - block
    - index
- Sort-Merge Join
- Hash Join

Simple Nested Loop Join
- 通过两层for循环，然后符合条件的进行输出
- IO计算：因为外层循环要读取 M 个 page,循环的tuple 是 m,内存循环要读取N个page，所以内层循环的IO数是 m * N,总的IO：M + (m * N)
- 假设 M = 1000, m = 10 0000, N = 500, n = 40000, 总的IO = 1000 + (10 0000 * 500) = 5000 1000
- 假设 SSD 执行速度 0.1ms 一次IO，大概需要1.3个小时
- 如果N是左表，那么总IO = 500 + (4000 * 1000) = 400 0500,大概需要1.1个小时
- 所以如果左表是小表，性能更好

```java
for (Tuple r: R) {
    for (Tuple s: S) {
        if (s.id == r.id) {
            // 输出
        }
    }
}
```

Block Nested Loop Join
- 对simple的优化，不在循环tuple，而是循环page，将page打包成block，然后循环block
- 这样的话对于内层循环来说IO就是 M * N，总的IO就是 M + (M * N)
- 假设 M = 1000, m = 10 0000, N = 500, n = 40000, 总的IO = 1000 + (1000 * 500) = 50 1000
- 假设 SSD 执行速度 0.1ms 一次IO，大概需要50s

```java
// 这个看上去循环多了，不过因为预先读取了两个block才循环，所以循环是在内存中，IO次数少了
for (Block br: R) {
    for (Block bs: S) {
        for (Tuple r: br) {
            for (Tuple s: bs) {
                if (s.id == r.id) {
                    // 输出
                }
            }
        }
    }
}
```

Block Nested Loop Join优化
- 假设buffer pool容量是B,可以先获取B - 2个左表的Block,剩下2个位置，一个是获取右表的 Block 的，一个是输出的。
- 这样的话总的IO次数：M + ([M/(B-2)] * N), M/(B - 2)向上取整
- 最好的情况是 B > M + 2，代表一次性能获取所有的左表的Block
- 这样总的IO就变成 M + N
- 假设 M = 1000, m = 10 0000, N = 500, n = 40000, 总的IO = 1000  + 500 = 1500
- 假设 SSD 执行速度 0.1ms 一次IO，大概需要0.15s


Sort Merge Join
- Sort：先对要join的字段进行排序
- Merge: 用两个指针进行匹配，如果数据匹配就输出，因为数据已经排序好了，所以只需要扫描一次就行了
- 这样的话总IO就是 sort io + merge io, merge io = M + N, sort io看具体的排序算法
- 最好的情况是要join的key本身已经是有序的了，那么只需要merge io = M + N,比如有索引，比如查询的时候使用了order by 

```java
sort R,S on join keys
cursorR = RSorted, cursorS = Ssorted;
while (cursorR && cursorS) {
    if (cursorR > cursorS) {
        // 相当于内层循环指向下一个
        cursorS++;
    }
    if (cursorR < cursorS) {
        // 相当于外层循环指向下一个
        cursorR++;
    }
    if (cursorR == cursorS) {
        // 输出 && 内层循环指向下一个
        cursorS++;
    }
}
```

Hash Join
- Build: 先对左表要join的key进行hash，构建一个hash table
- probe: 在对右表要join的key进行hash, hash相同的会放入同一个 bucket,也就完成了匹配

Hash Join优化
- 可以添加 `布隆过滤器` 来优化，这样的话在probe阶段，对右表的key， hash以后先查询布隆过滤器，如果false，就不需要在放入hash table去匹配了
- 如果true在去hash table里面匹配数据完成输出

Grace Hash Join
- 在 hash join中，只构建一个hash table来存储左表数据，右表的hash完成直接匹配
- Grace hash join中，构建两个hash table，然后进行 nested loop join
- 总的IO： 3(M + N)

## query exec

processing Method
- Iterator Model: 大多数数据库使用的
- Materialization Model：Iterator Model的一个特定版本，用在内存型数据库
- Vectorized/ Batch Model：Iterator Model差不多，要传入一大堆东西， 分析型用的多

Iterator Model
- 像java的stream， 流的方式执行
- 先构建执行树，上层的通过`next`方法调用下层的方法并接收返回值

Materalization Model
- 去掉了`next`方法，使用了`output`方法，一次输出所有数据给上层

Vectorized Model
- 使用`next`方法，但是一次性返回一堆 tuples, 数量取决于 Buffer pool 大小
- 使用OLAP，大多数的数仓使用这个

Access Method
- 顺序扫描
- 索引扫描
- 多索引扫描

Zone Maps
- 通过在page上面增加一个元数据，存储min,max,avg,count,sum信息
- 当查询的时候比如where val > 600,先查询 Zone Maps，如果发现max < 600，那么就不用在扫描这个page了
- 缺点是插入，更新，删除的时候还需要更新Zone Maps信息，所以适用于 OLAP数据库

late materialization
- 已经不需要的字段就不在往上层传了

Expression Evaulate
- 先建立where条件的 Expression tree,中间节点是操作符，比如`=`,`>`,`<`,`and`,`or`等。子节点是两边的值
- 对于每个tuple执行这个表达式
- 好的数据库会对表达式进行优化，比如优化成常量，像where 1 = 1优化成 trues


Process Models
- Process per DBMS Worker
- Process Model
- Thread per DBMS Worker

Process per DBMS Worker
- 每个进程是一个worker,负责执行任务
- 通过`共享内存`进行buffer pool的通信，要不然每个进程都会有一个buffer pool。
- 老得数据库大部分使用的这个，因为当时没有统一的线程API,像DB2,oracle,postgraSQL

Process Model
- 和 Process per DBMS Worker一样
- 但是增加了 worker pool，有多个worker进行调度处理
- 像DB2,postgraSQL（2015）

Thread per DBMS Worker
- 一个进程，多个线程执行，由数据库自己控制线程。
- 现在的数据库几乎都使用这种，像DB2, MSSQL, MySQL, Oracle(2014)

Intra query parallelism
- Intra operator(水平)
- Intra operator(垂直)
- Bushy

Intra operator(水平)
- 通过水平拆分数据，由多个线程执行，比如3个线程，一个线程处理一个page，以此类推
- 处理完成以后通过`exchange operator`来进行合并，拆分也是通过它。

Exchange operator
- Gather:从多个线程的结果合并成一个输出流
- Repartition: 重新组织多个输入流到多个输出流的数据，像group by
- Distribute: 拆分一个输入流到多个输出流

## 查询计划

查询优化
- 静态规则/条件触发
    - 根据静态的规则，或者触发了某一个条件来重写查询，移除低效率的东西
    - 需要检查catalog查看信息，而不需要去检查数据
- 成本原则
    - 使用模型预估查询成本
    - 估计出多个查询计划，选择其中成本最低的一个

查询结构
- SQL rewrite (可选)：重写sql语句，对sql语句进行优化
- Parser: 解析SQL查询，构建语法树
- Binder: 查询catalog信息，并将表名等信息替换成内部标识，生成`逻辑查询计划`
- Tree rewrite (可选)：重写树结构，包括关系代数等
- Optimizer: 调用成本模型，预估成本，选择合适的执行计划，生成`物理执行计划`

### 查询优化

> 查询优化是很难的，有些数据库的查询优化做的很差，DB2曾引入机器学习做查询优化，效果并不好，被吐糟安装DB2要做的第一件事就是关掉这个功能

关系代数等价
- 一个查询语句可以用多个关系代数来表示
- 可以选择其中代价更小的那个关系代数
- 这个被叫做 `query rewriting` 属于上面的 `Tree rewrite`阶段

predicate pushdown
- 比如select a.name,b.code from a join b where a.name = 'abc'
- 可以先join在where，也可以先where 再 join
- 显然先where更好，把where放到join的下层执行
- 还有可以再where之后只获取需要的列，其余不需要的列就不再往上层传递了

语句重写
- 比如select * from a where 1 = 0; 那么不会返回任何数据。
- select * from a where 1 = 1 会返回所有数据，重写成select * from a

> mongoDB没有使用成本预测模型，而是执行所有的查询计划，哪个最先返回就用哪个

catalog会记录一些成本信息，不同的DBMS有不同的更新策略，也可以手动更新,这被叫做`statistics`
- PostgreSQL/SQLite : ANALYZE
- Oracle/ Mysql: ANALYZE TABLE
- SQL server: UPDATE STATISTICS
- DB2: RUNSTATS

statistics: 维护着下面的信息
- counter: 表中的tuple数量
- V(A,R): R表中的A字段的去重数量
- SC(A,R): `选择基数SC` 是 counter / V(A,R) 的值

选择率：有了上面的数据，就可以计算出要查询的数据的分布比例了。这里就是求概率。
- 比如查询主键 id = 1的数据，当前有数据5条，那么counter = 5,V(A,R) = 5, SC(A,R) = 1, 选择率 = 1/5
- 比如范围查询 id > 2的数据，当前有数据5条，那么counter = 5, V(A,R) = 5, SC(A,R) = 1, 选择率 = (Max - A) / (Max - Min) = 5-2/5-1 = 3/4,显然这事错误的预测，但是数据库就是这样
- 比如not查询 id <> 1的数据，当前有数据5条，那么选择率 = 1 - (id = 1的选择率) = 1 - 1/5 = 4/5
- 比如多个条件 and, 那么取交集，也就是 两个选择率 相乘 = sel(AB),这种计算同样不太准确，比如有一个`汽车表`，有`make`字段代表生产商，`model`代表型号，我们知道model = "帕萨特"，make 一定是 `大众`。按照我们的算法 假设make 有10个，选择率就是1/10, model 100个，选择率就是 1/100,总的选择率就是 1/1000,但是帕萨特一定是大众的，所以真实选择率其实是1/100。有些数据库可以设置字段关联来解决这个问题，比如oracle等，mysql和postgresql不行。
- 比如多个条件 or, 那么取并集，也就是两个选择率相加 = sel(A) + sel(B) - sel(AB)

直方图的存储，由于存储所有信息的直方图可能很占空间，可以选择稀疏存储，合并一些数据，这样会牺牲一些准确率，但是节省空间。

除了直方图以外，有些数据库还会使用抽样检查，花费一些时间进行抽样，然后根据样本来进行预测选择率。

单表查询
- 索引搜索
- 二分搜索
- 顺序搜索

对于单表查询来说，一般会使用`启发式规则`，他来判断哪些where条件能筛掉更多的数据，就先进行哪个where。

`sargable (search argument able)`：他会比较不同的索引，比如这个索引合适，那么就会使用它，比如id=1的，那么就会使用主键索引


## 并发控制原理

原子性：事务的每个操作都是原子的

当转账的时候，事务被突然的中止，或者断电，该怎么做？
- Logging
- shadow paging

Logging
- 记录所有的操作，使得事务中止或者故障后可以undo 操作。
- 在磁盘和内存中维护 undo records
- 就像飞机上的黑盒子一样

shadow paging
- 
- 起源于System R
- CouchDB和LMDB使用这个方法


一致性：保证事务执行前和执行后是一致的，中间可以临时不一致，但最终要一致。

隔离性：保证事务的隔离性，每个事务都是独立运行的，并发的时候通过`并发控制协议`来保证交错执行，通过latch保证正确性。

并发控制协议：
- 悲观的：两阶段提交
- 乐观的：时间戳

顺序执行：
- 顺序执行每个事务，保证事务的最终一致性

交错执行：
- 如果能达到顺序执行的结果，那么就是正确的执行 schedle

图片

读写冲突（不可重复读）：当读第一次的时候，值被其他事务改变了，再次读的时候，值就和第一次读的时候不一样了

图片

写读冲突（读未提交或脏读）：A事务读取后，修改了值，B事务读取了修改的值，然后又修改了值，B事务提交后，A事务中止，回滚。

图片

写写冲突（覆盖数据）：两个事务同时写入一个值，有一个值会被覆盖掉。

图片

冲突可串行化
- 通过比较两个操作是否冲突，来修改顺序
- 使用依赖图（优先图）来判断依赖是否出现环


## 两阶段锁

事务A现获取锁，事务B等待锁，事务A执行完成以后，释放锁，事务B才能拿到锁。

图片

共享锁，读锁，S-LOCK
独享锁，写锁，X-LOCK

两阶段锁,遵循这个方法，使得事务是 冲突可串行化 的，但是会有级联事务中止（cascading aborts），可以通过强严格两阶段锁解决这个问题。
- Growing:每个事务从lock manager获取锁
- Shrinking:事务释放锁以后不能获取新锁

### 严格两阶段锁

在提交事务的时候才释放锁。可以解决脏读的问题。

非两阶段锁执行如下：

图片

两阶段锁执行如下：

图片

严格两阶段锁执行如下：

图片

### 死锁

死锁检测：通过使用`wait-for`图来检测依赖关系，如果有环就是死锁

检测的频率可以通过参数调整，这个需要权衡

victim选择
- 可以根据时间戳
- 根据持有锁的数量
- 根据已完成的工作量
- 根据剩余的工作量

根据时间戳来选择
- wait die
- wound die

图片

## 时间戳并发控制

两阶段锁是一种`悲观`的协议，所有人都会上锁，会争抢，时间戳是一种不依赖锁的`乐观`的协议。

Ti代表事务i得一个时间戳，Tj是j的，如果Ti < Tj，那么i得事务会在j之前提交。

时间戳的两个特性
- 唯一性，每个时间戳必须是唯一的
- 单调递增性，时间戳必须是增加的

### 基本时间戳协议

每个tuple需要维护两个时间戳，一个`读时间戳`，一个`写时间戳`。

#### 读

在读取的时候要保证，当前时间戳 > 写时间戳，也就是读取的是最新的值，未来不会被改变的值。
如果 当前时间戳 < 写时间戳，那么重启事务，分配一个新的时间戳，再试一次。
如果成功取到tuple，那么需要更新`读时间戳`，使用自己的时间戳和原来的时间戳中大的那个去更新。

#### 写

写入的时候要保证，当前时间戳 > 读时间戳 并且 > 写时间戳
成功写入的时候要更新写时间戳，使用自己的时间戳和原来的时间戳中大的那个去更新。

#### 托马斯写入优化

在写入的时候，如果当前时间戳 < 写入时间戳，本来应该`中止`的事务，可以继续执行，但是写入操作不写入数据库，因为数据库的数据是更新的，而是写入本地副本，方便这个事务后面使用。

### 乐观并发控制

另外一个是`乐观并发控制`。为每一个事务创建一个私有空间，他的所有操作都是先对私有空间的副本操作，最后执行到数据库里面的时候需要对比一下，是否能执行。如果不冲突，就可以执行。

三个阶段
- read phase(work phase): 执行事务的操作，操作都在私有空间执行。
- validation phase: 提交事务的时候验证事务的有效性，是否冲突等，确实是否可以提交。在这个阶段才会分配时间戳。如果在之前需要写入时间戳，先暂时写入无穷大。
- write phase: 把事务的操作写入数据库里面，这是原子的。

数据库拥有全局视野，在validation phase阶段，是单线程比较事务是否可以执行，会有一个大的latch上锁
- backward validation: 和并发执行中更早提交的事务进行比较
- forward validation: 和并发执行中后面没有提交的事务进行比较

### partition based 时间戳协议

按照时间戳水平分区，在同一个区里面，按照时间戳顺序执行，就不需要latch了。速度会很快。

在不同区执行的话，就很复杂了。

每个分区都是单线程执行的。这样不需要获取latch。

幻读，层级锁，间隙锁，index lock

## 多版本并发控制（MVCC）

MVCC最早在1978年由一位MIT的Phd学生提出。在1980年被数据库实现。

firefox 最开始叫 phoenix， 但是因为和其他的重名了需要改名字，然后改成了firebird, firebird是个最早开源的数据库，它使用了MVCC,所以火狐还要改名，就成了firefox。

- Writers don't block readers
- Readers don't block wirters

只读事务读取快照，不需要锁。

版本维护有3个元数据
- version 版本号 从0开始，递增
- begin 开始的时间戳
- end 结束的时间戳，默认是无穷大，当写入以后要更新上一个版本的end

版本存储：为每个tuple创建一个链表，每个事务通过指针遍历链表获取对应的版本。索引指针指向链表的头节点。
- append only storage: 复制一个tuple,更新数据，放到后面的节点作为tuple的新版本。
- time travel storage: master version表中放最新版本的数据，老版本的数据放在 time travel 表中。master version表维护指向time travel表数据的指针。
- Delta Storage: 最佳方案，只维护对前一个版本数据的修改，不直接维护所有副本。

garbage collection(垃圾回收)
- tuple level：通过比较时间戳来确定哪些版本已经不用了，可以进行回收了。
- transaction level

索引管理
- 逻辑指针：通过中间表转化指针和物理地址，二级索引指向主键索引。
- 物理指针：直接记录指针

MySQL使用两阶段锁，版本存储使用Delta Storage，垃圾回收是tuple level Vacuum,索引管理是逻辑指针。Mysql更快。
PostgreSQL使用两阶段锁，版本存储使用append only storage, 垃圾回收使用tuple level Vacuum，索引管理是物理指针。

## Logging Schemes

在数据库运行时，还没有把数据写入磁盘的时候发生故障，这个时候需要恢复数据。

### 故障恢复

主要是两件事
- 收集日志信息，以方便恢复
- 根据日志信息进行恢复

故障类型
- 事务故障
- 系统故障

### UNDO(撤销) and REDO(重做)

Undo:维护一些信息，可以恢复事务对数据库中某个对象所做的任何修改。
Redo: 维护一些信息，可以重新执行某个事务对数据库中的某个对象所做的修改。可以重新执行一个已经提交的事务的修改。

### buffer pool 策略

图片

两个策略
- steal:是否允许一个已提交事务写入磁盘的时候把这个page里面的未提交事务的修改也写入磁盘。
- force：提交事务的时候，是否允许事务的所有更新写入磁盘

not steal + force
- 优点：不需要恢复，因为只写入磁盘提交的事务更新的内容。磁盘就是已提交内容
- 缺点：多个事务提交需要写入多次磁盘，写入磁盘麻烦点，因为要复制一个副本出来，副本中是这个事务修改的内容，把这个副本写入磁盘。

shadow paging:
- 有一个db root，记录当前使用的hash table
- hash table有一个master table是当前使用的，每个事务会有一个shadow page table，提交以后更新db root指向这个shadow page table，然后回收之前的master table和对应的page文件

wirte ahead log
- 先写入日志，在写入磁盘
- 日志中包含的信息可以用来undo and redo。
- 使用的策略是 steal + not force，所以不需要把事务的所有更新都写入磁盘。

日志内容
- 事务id
- 对象id
- 时间戳
- before value(undo)
- after value(redo)
- 写入更快，但是恢复速度慢

gorup commit
- 有两个log buffer，写满一个以后，写另一个，将满的log buffer写入磁盘
- 出了满的时候写入磁盘，还有定时，如果知道写入磁盘的时间，可以定时成这个时间，没满的话时间到了也会写入磁盘。

logging schemes
- 物理日志：记录底层字节的修改，就像git diff一样能看见，但是修改1万条tuple,就会记录1万条tuple的修改。
- 逻辑日志：记录高层的事务操作，像update,delete,insert等。比物理日志省空间，但是恢复的时候不知道哪些tuple已经写入了磁盘，所以恢复的时候还会在写入一遍。
- 混合日志：记录相对底层的修改，但是不像git diff一样那么详细。

图片

### check point

日志中写入check point，check point之前的都是已经写入磁盘的，所以恢复的时候就不用管了。

## aries recovery

三步
- 预写式日志
- Repeating history during redo: 重启并恢复事务到之前的状态
- logging changes during undo：再次写入预写式日志

日志序列号(LSN)
- 每个日志都要有一个序列号，在一个事务中，可能不是连续的，但是递增的。
- flushedLSN:在内存中，记录上一个刷到磁盘中的log的LSN
- pageLSN: 在page中，记录page最新的序列号
- recLSN: 在page中，记录最老的序列号，这个是不会变的，而pageLSN一直在更新。
- lastLSN: 记录事务中最新的一个日志
- Master Record: check point最新的LSN

事务提交的时候，往日志里面写入一个`txn end`。

CLR:abort算法
- 当事务abort的时候，进行撤销操作，日志里面添加CLR记录，before是对应的之前事务日志的after，CLR的after对应之前的before,undo next指针指向下个需要撤销的日志。
- 撤销完成以后添加 `txn end`。

图片

check point写入
- 第一种方式是停止创建新事务，等所有事务完成的时候开始写入
    - 优点是能完全保证数据一致性
    - 缺点是耗时，执行的时候不能创建新事务
- 第二种方法暂停更新的事务，只读事务不受影响，需要维护一个active transation table和一个dirty page table
    - active transation table包含事务id,lastLSN和状态，状态有运行中，提交中，等待undo
    - dirty page table 包含所有的dirty page信息
- 第三种方法最好，叫fuzzy checkpoint，checkpoint的时候允许所有事务运行。
    - 开始的时候记录checkpoint begin
    - 结束的时候记录checkpoint end,end里面包含了 checkpoint期间的active transation table和dirty page table信息。

图片

arise recovery
- 分析：根据master record跳到对应的check point的位置，然后开始扫描需要恢复的信息。
- redo: 重新执行所有的操作。
- undo: 从日志最后开始往上，撤销所有未提交的更改。这个时候已提交的已经写入磁盘，未提交的已经被撤销。

分析阶段：从master record的位置开始扫描到最后，找出这之间的所有active transation table和dirty page table信息。

图片

redo: 根据分析出的信息，找到dirty page中最早的一个recLSN, 也就是最早的一个日志，然后从这里开始恢复数据，执行一遍所有的操作。来恢复buffer pool。

图片

undo: 从最后开始往上面扫描，把需要撤销的数据进行撤销。

图片

## 分布式数据库介绍

系统架构
- shared everthing
- shared memory:常见于高性能计算领域，有多个CPU，共享内存和磁盘
- shared disk: 内存也有多个，共享磁盘，这个更常见，例如云数据库
    - 更新数据的时候需要通知其余的节点
- shared noting: 磁盘也是多个
    - 有更好的效率，但是很难保证数据一致性和扩容


mongo
- route节点，负责把请求路由到对应的节点上
- config节点，route从这里获取请求应该到哪个节点上
- db节点

数据拆分
- 将不同的数据放到每个shared上面
- 不同的查询交给不同的shared去做，可以通过exchange operate来并行执行。
- 最简单的方式是一个表一个分区，mongodb可以这样。
- 水平分区
    - 将数据水平分到每个分区中
    - 可以是hash，也可以是一个范围一个范围的分区
    - hash的话，想增加分区很麻烦，可以使用`一致性hash`来解决增加分区的问题，而不是取余。

分布式事务
- 通过中心化服务器，来分发lock，然后提交事务的时候通过他来请求每一个分区是否能提交事务，如果都可以，才提交事务
- 去中心化事务提交

## 分布式OLTP数据库

原子提交协议
- 两阶段提交
- 三阶段提交
- Paxos
- Raft
- ZAB

两阶段提交
- 第一阶段 prepare, 像所有参与者发送请求，是否能提交事务，只有所有都可以提交，才进入第二阶段，如果有一个节点abort,那么事务就会进入第二阶段abort
- 第二阶段 commit, 想所有参与者发送请求，进行提交事务。
- 第二阶段 abort, 返回abort，然后所有参与者abort。

图片


优化
- early prepare voting: 最后一个查询执行的时候，告诉他可以直接进入prepare阶段
- early: prepare阶段结束就返回事务执行成功，然后自己再接着commit。

如果协调器崩溃了。要么全部abort，要么选出新的协调器继续执行事务。

Paxos，来自分布式计算领域，也被称为`共识协议`。两阶段提交是Paxos的一个子集。
- Paxos大部分节点同意提交就可以提交，而两阶段提交需要所有参与者同意，所以Paxos没有容错。

图片
multi-Paxos
- 选举一个leader来进行提案，每隔一段时间重新选举
- 防止有两个 proposer 来回提交导致的starving问题

两阶段提交 vs Paxos

图片

replication
- master-replica: 比如主从复制，读写分离这种
- multi-master-replica: 这种方案所有副本都可以读写，冲突的时候通过两阶段提交或者Paxos来觉得写入哪个。Facebook使用了这个。

K-safety: 通过监控对象来看有哪些replica是活跃的。至少要有k个replica，如果小于k个，就认为宕机了。

propagation scheme
- 同步：强一致性，从节点都同步以后才返回成功
- 异步：最终一致性，先返回成功，在同步从节点

CAP理论
- Consistent: 一致性
- Always Available: 始终可用
- Network Partition Tolerant:分区容错性

Nosql基本都是AP,事务性的基本都是CA或CP


## 分布式OLAP数据库

OLAP数据库也被称作`数据仓库`，通过ETL，把数据存入数据仓库。
- Extract
- Transform
- Load

星形模型
- 一个事实表
- 几个dim表

雪花模型
- 一个事实表
- 更多的dim表，dim表可以有他的dim表

查询执行
- push: 发送查询到包含数据的节点,返回数据的时候会做过滤和处理，就像`条件下推`那样
- pull: 知道需要的数据在哪些page里面，把page取过来在执行查询。

push

pull

查询计划
- 物理操作： 先生成查询计划，然后将对应的需要执行的物理操作直接发送给其余节点，其余节点只负责执行，返回数据。大部分分布式数据库都这样。
- sql: 将sql发给每个节点，每个节点生成自己的执行计划。然后执行返回。




