---
title: 数据库系统原理第十节
date: 2021-08-15 10:12:47
tags: ['数据库','数据库原理','sql','mysql']
category: 数据库系统原理
article: 数据库系统原理第十节
---

# 数据库系统原理第十节

## 数据库设计

### 数据查询

#### 视图

什么是视图
- 视图是一个对象，他是数据库提供给用户的以多种角度观察数据库中数据的一种重要机制
- 视图不是数据库中真实的表，而是一张虚拟表，其自身并不存储数据

视图的优点
- 集中分散数据
- 简化查询语句
- 重用SQL语句
- 保护数据安全
- 共享所需数据
- 更改数据格式

##### 创建视图

or replace 防止报错，存在替换，不存在创建
with check option 增删改查的时候检查视图条件

```SQL
create or replace view view_name [(col_list)]
as select_statement
with check option
```

##### 删除视图

drop view view_name


##### 修改视图

```SQL
alter view view_name [(col_list)]
as select_statement
with check option
```

##### 查看视图定义

```SQL
show create view view_name
```

##### 更新视图数据

```SQL
insert into table_name 
values(value1,...);
```

```SQL
update table_name set col_name = 'value'
```

###### 删除视图数据

```SQL
delete from table_name where ...
```

###### 查询视图数据

select 

## 数据库编程

### 存储过程

`存储过程` 是一组为了完成某项特定功能的 `SQL语句集`
- 可增强SQL语言的功能和灵活性
- 良好的封装性
- 高性能
- 可减少网络流量
- 可作为一种安全机制来确保数据库的安全性和数据的完整性
其实质就是一段存储在数据库中的 `代码`
它可以由声明式的sql语句和过程式sql语句组成

#### 创建存储过程

DELIMITER $$ //用户定义的MYSQL 结束符

参数：in|out|inout 参数名 参数类型

```SQL
DELIMITER $$
create procedure sp_name(参数)
BEGIN
body //存储过程代码
END $$
```

#### 调用存储过程

call sp_name(参数)

#### 删除存储过程

drop procedure sp_name



## 

latch carbbing
- 使用栈保存latchs
- 每个节点都需要一个latch
- 如果当前节点是`安全`的，就可以释放上层的所有latchs
- `安全`：指操作的时候不会触发`拆分`和`合并`。通常read latch都是安全的，write latch 插入的时候如果有足够的空间就是安全的，删除的时候删除以后不会合并就是安全的

乐观锁
- 乐观的认为不需要`合并`和`拆分`。
- 所有的操作都先获取read latch,如果发现需要`合并`和`拆分`，再次从头获取write latch来一遍
- 优点是所有操作都是read latch，可以更好的支持并发
- 缺点是遇到`合并`和`拆分`会再来一遍，而且如果连续的插入都需要合并，就会退化成每个都获取write latch。

叶子节点扫描
- 叶子节点的扫描可能会触发`死锁`，比如两个线程
- 线程1执行读取，读取到了叶子节点1
- 线程2执行写入，在叶子节点2处获取了write latch
- 这个时候线程1在叶子节点1里面没有找到数据，所以要扫描叶子节点2，但是获取read latch的时候卡主了，需要等待
- 而线程2有可能也需要访问叶子节点1，同样等待，产生死锁
- 这个时候可以设置等待时间，超过等待时间则`自杀`，然后重头再来，加入线程1自杀，然后再来一遍，这个时候线程2就可以获取到latch，然后执行下去了

overflow处理
- 来源于b link tree的优化
- 当需要拆分的时候，先拆分叶子节点，这个时候不向`父结点`传播，因为修改父结点需要从头开始获取write latch。
- 这个时候标记父结点需要插入一个key
- 等待下一个修改操作到父结点的时候，获取write latch，然后执行这个插入操作。

## 排序和聚合

排序的好处
- 有序的数据创建索引的时候可以快速的先创建叶子节点，在创建父结点
- 有序的数据在`order by`分组的时候可以更快的分组
- 有序的数据在`distinct`去重的时候可以更快的去重

排序算法
- 在内存中
    - 可以使用各种算法
    - 但是有的数据内存放不下，就需要在磁盘上排序
    - 需要先知道`可以用内存的大小`，这样就知道该内存排序还是磁盘排序
- 在磁盘上
    - 快排会产生更多的随机IO,会更慢
    - 使用`归并排序`更好，分成多个`runs`,对每个run排序，然后在通过`二路归并`生成总的排序，这可以减少随机IO
    - 外部归并排序，需要3个`buffer pool`，2个用来排序run，1个用来二路归并。 
    - 次数：1 + log(n)
    - 总的IO数: 2N * (# of passes)
    - 可以通过`预取`来优化，当对page排序的时候，另外一个线程先取出下次要排序的page。

聚簇索引
- 排序的字段如果建立了聚簇索引，就不需要在排序了，直接可以走聚簇索引拿到排序好的数据

### 聚合

两个实现方法
- 排序
- 哈希，通常哈希更好，因为都在内存中

> group by 和 distinct 本身执行的时候也是需要排序的

hash
1. 分区
    - 可以顺序扫描每个page
    - 对于每个page的key进行hash，然后分区，hash相同的说明key相同，分到一个区里面
    - 这个时候不管distinct还是group by都可以方便的执行了
2. 重新哈希
    - 对于分区以后的数据再次进行hash
    - 再次hash的数据放入一个临时的hash table
    - 处理完一个临时的hash table就把结果写入结果集

排序的聚合实现，以distinct为例：
1. 先执行where条件筛选出符合的`tuple`
2. 再次根据列筛选出符合的列
3. 对于需要排序的列进行排序
4. 顺序扫描排序结果，实现去重，并生成最终结果

哈希的聚合实现，以distinct为例：
1. 先执行where条件筛选出符合的`tuple`
2. 再次根据列筛选出符合的列
3. 对于需要排序的列进行hash，先分区，再重新哈希。
4. 重新哈希的时候生成最终结果。

重新哈希的时候
- avg的话，需要再临时hash table里面存储key的数量和要求平均数的总数。在生成最终结果的时候进行计算平均数
- min的话，临时hash table里面存入最小数，生成最终结果直接取
- max同上
- sum同上
- count同上

## join算法

join输出：数据
- 在join的时候把两张表的数据全部输出给下一个处理器，这包括了表的所有字段
- 好处是，接下来的处理不需要再拿其他字段了，所有字段都有了
- 坏处是，Join的时候数据量很大，因为有所有字段
- 可以进行优化，在join的时候只获取需要的字段

join输出：record id
- 在join的时候，只获取on的字段和record id，然后需要其他字段的时候在通过 record id去获取，这个很适合列存储数据库
- 第一个使用的是`vertica`列存储数据库，不过现在已经不用了

如何判断两个join算法的好坏？
- 通过IO来计算
- 假设左表R有M个page,m个tuple
- 右表S有N个page,n个tuple

join算法
- Nested Loop Join
    - simple/stupid
    - block
    - index
- Sort-Merge Join
- Hash Join

Simple Nested Loop Join
- 通过两层for循环，然后符合条件的进行输出
- IO计算：因为外层循环要读取 M 个 page,循环的tuple 是 m,内存循环要读取N个page，所以内层循环的IO数是 m * N,总的IO：M + (m * N)
- 假设 M = 1000, m = 10 0000, N = 500, n = 40000, 总的IO = 1000 + (10 0000 * 500) = 5000 1000
- 假设 SSD 执行速度 0.1ms 一次IO，大概需要1.3个小时
- 如果N是左表，那么总IO = 500 + (4000 * 1000) = 400 0500,大概需要1.1个小时
- 所以如果左表是小表，性能更好

```java
for (Tuple r: R) {
    for (Tuple s: S) {
        if (s.id == r.id) {
            // 输出
        }
    }
}
```

Block Nested Loop Join
- 对simple的优化，不在循环tuple，而是循环page，将page打包成block，然后循环block
- 这样的话对于内层循环来说IO就是 M * N，总的IO就是 M + (M * N)
- 假设 M = 1000, m = 10 0000, N = 500, n = 40000, 总的IO = 1000 + (1000 * 500) = 50 1000
- 假设 SSD 执行速度 0.1ms 一次IO，大概需要50s

```java
// 这个看上去循环多了，不过因为预先读取了两个block才循环，所以循环是在内存中，IO次数少了
for (Block br: R) {
    for (Block bs: S) {
        for (Tuple r: br) {
            for (Tuple s: bs) {
                if (s.id == r.id) {
                    // 输出
                }
            }
        }
    }
}
```

Block Nested Loop Join优化
- 假设buffer pool容量是B,可以先获取B - 2个左表的Block,剩下2个位置，一个是获取右表的 Block 的，一个是输出的。
- 这样的话总的IO次数：M + ([M/(B-2)] * N), M/(B - 2)向上取整
- 最好的情况是 B > M + 2，代表一次性能获取所有的左表的Block
- 这样总的IO就变成 M + N
- 假设 M = 1000, m = 10 0000, N = 500, n = 40000, 总的IO = 1000  + 500 = 1500
- 假设 SSD 执行速度 0.1ms 一次IO，大概需要0.15s


Sort Merge Join
- Sort：先对要join的字段进行排序
- Merge: 用两个指针进行匹配，如果数据匹配就输出，因为数据已经排序好了，所以只需要扫描一次就行了
- 这样的话总IO就是 sort io + merge io, merge io = M + N, sort io看具体的排序算法
- 最好的情况是要join的key本身已经是有序的了，那么只需要merge io = M + N,比如有索引，比如查询的时候使用了order by 

```java
sort R,S on join keys
cursorR = RSorted, cursorS = Ssorted;
while (cursorR && cursorS) {
    if (cursorR > cursorS) {
        // 相当于内层循环指向下一个
        cursorS++;
    }
    if (cursorR < cursorS) {
        // 相当于外层循环指向下一个
        cursorR++;
    }
    if (cursorR == cursorS) {
        // 输出 && 内层循环指向下一个
        cursorS++;
    }
}
```

Hash Join
- Build: 先对左表要join的key进行hash，构建一个hash table
- probe: 在对右表要join的key进行hash, hash相同的会放入同一个 bucket,也就完成了匹配

Hash Join优化
- 可以添加 `布隆过滤器` 来优化，这样的话在probe阶段，对右表的key， hash以后先查询布隆过滤器，如果false，就不需要在放入hash table去匹配了
- 如果true在去hash table里面匹配数据完成输出

Grace Hash Join
- 在 hash join中，只构建一个hash table来存储左表数据，右表的hash完成直接匹配
- Grace hash join中，构建两个hash table，然后进行 nested loop join
- 总的IO： 3(M + N)

## query exec

processing Method
- Iterator Model: 大多数数据库使用的
- Materialization Model：Iterator Model的一个特定版本，用在内存型数据库
- Vectorized/ Batch Model：Iterator Model差不多，要传入一大堆东西， 分析型用的多

Iterator Model
- 像java的stream， 流的方式执行
- 先构建执行树，上层的通过`next`方法调用下层的方法并接收返回值

Materalization Model
- 去掉了`next`方法，使用了`output`方法，一次输出所有数据给上层

Vectorized Model
- 使用`next`方法，但是一次性返回一堆 tuples, 数量取决于 Buffer pool 大小
- 使用OLAP，大多数的数仓使用这个

Access Method
- 顺序扫描
- 索引扫描
- 多索引扫描

Zone Maps
- 通过在page上面增加一个元数据，存储min,max,avg,count,sum信息
- 当查询的时候比如where val > 600,先查询 Zone Maps，如果发现max < 600，那么就不用在扫描这个page了
- 缺点是插入，更新，删除的时候还需要更新Zone Maps信息，所以适用于 OLAP数据库

late materialization
- 已经不需要的字段就不在往上层传了

Expression Evaulate
- 先建立where条件的 Expression tree,中间节点是操作符，比如`=`,`>`,`<`,`and`,`or`等。子节点是两边的值
- 对于每个tuple执行这个表达式
- 好的数据库会对表达式进行优化，比如优化成常量，像where 1 = 1优化成 trues


